{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv('iris.csv')\n",
    "\n",
    "iris_df.info()\n",
    "print(iris_df.isnull().sum())\n",
    "iris_df = iris_df.dropna()\n",
    "\n",
    "# Examinar os primeiros registros para entender a estrutura dos dados\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treinamento: 105\n",
      "Tamanho do conjunto de teste: 45\n"
     ]
    }
   ],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X = iris_df.drop('species', axis=1)  # Features\n",
    "y = iris_df['species']  # Alvo\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Tamanho do conjunto de treinamento:\", X_train.shape[0])\n",
    "print(\"Tamanho do conjunto de teste:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de características sem normalização:\n",
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "81            5.5          2.4           3.7          1.0\n",
      "133           6.3          2.8           5.1          1.5\n",
      "137           6.4          3.1           5.5          1.8\n",
      "75            6.6          3.0           4.4          1.4\n",
      "109           7.2          3.6           6.1          2.5\n",
      "..            ...          ...           ...          ...\n",
      "71            6.1          2.8           4.0          1.3\n",
      "106           4.9          2.5           4.5          1.7\n",
      "14            5.8          4.0           1.2          0.2\n",
      "92            5.8          2.6           4.0          1.2\n",
      "102           7.1          3.0           5.9          2.1\n",
      "\n",
      "[105 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train_unnormalized = X_train\n",
    "X_test_unnormalized = X_test\n",
    "\n",
    "print(\"Dados de características sem normalização:\")\n",
    "print(X_train_unnormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de características normalizados:\n",
      "[[-0.4134164  -1.46440146 -0.10014569 -0.32149987]\n",
      " [ 0.55122187 -0.49582097  0.71771076  0.35364985]\n",
      " [ 0.67180165  0.2306144   0.95138404  0.75873969]\n",
      " [ 0.91296121 -0.01153072  0.30878254  0.21861991]\n",
      " [ 1.63643991  1.44134002  1.30189395  1.7039493 ]\n",
      " [-0.17225683 -0.25367584  0.1919459   0.08358997]\n",
      " [ 2.11875905 -0.01153072  1.59398554  1.16382952]\n",
      " [-0.29283662 -0.01153072  0.36720086  0.35364985]\n",
      " [-0.89573553  1.19919489 -1.443767   -1.40173942]\n",
      " [ 2.23933883 -0.49582097  1.65240385  1.02879957]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dados de características normalizados:\")\n",
    "print(X_train_normalized[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "versicolor    37\n",
      "virginica     37\n",
      "setosa        31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dados sem balanceamento\n",
    "\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "versicolor    37\n",
      "virginica     37\n",
      "setosa        37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balanceando os dados\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanceado, y_train_balanceado = smote.fit_resample(X_train, y_train)\n",
    "print(y_train_balanceado.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo desbalanceado: 1.0\n"
     ]
    }
   ],
   "source": [
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "previsoes = modelo.predict(X_test)\n",
    "acuracia = accuracy_score(y_test, previsoes)\n",
    "print(\"Acurácia do modelo desbalanceado:\", acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo balanceado: 1.0\n"
     ]
    }
   ],
   "source": [
    "modelo_balanceado = LogisticRegression()\n",
    "modelo_balanceado.fit(X_train_balanceado, y_train_balanceado)\n",
    "previsoes_balanceadas = modelo_balanceado.predict(X_test)\n",
    "acuracia_balanceada = accuracy_score(y_test, previsoes_balanceadas)\n",
    "print(\"Acurácia do modelo balanceado:\", acuracia_balanceada)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
